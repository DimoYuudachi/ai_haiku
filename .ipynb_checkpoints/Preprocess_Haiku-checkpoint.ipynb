{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85bd1bb-d23b-4d9f-bfcd-efa6d4ccc80a",
   "metadata": {},
   "source": [
    "# データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1a4f07a-3e3c-4152-88a4-119a98a49d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Flask導入された\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# MatplotlibおよびSeabornで日本語を表示可能にする\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'MS Gothic'\n",
    "\n",
    "# 高解像度なPNGでグラフを出力する\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "from flask import Flask\n",
    "print(\"Flask導入された\")\n",
    "\n",
    "import pyopenjtalk\n",
    "import pykakasi\n",
    "from sudachipy import tokenizer, dictionary\n",
    "import pyopenjtalk\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8868c9e9-227b-4464-b553-cce9c9e2b41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "片仮名: ワタシワガクセーデス\n"
     ]
    }
   ],
   "source": [
    "kana_kata = pyopenjtalk.g2p(\"私は学生です\", kana=True)\n",
    "print(\"片仮名:\", kana_kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91daae96-46cc-4dd5-80b6-5bd85fc6a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "わたしわがくせーです\n"
     ]
    }
   ],
   "source": [
    "kks = pykakasi.kakasi()\n",
    "kks.setMode(\"K\", \"H\")  # カタカナを平仮名に変換\n",
    "conv = kks.getConverter()\n",
    "kana_hira = conv.do(kana_kata)\n",
    "print(kana_hira)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e177e1-ec86-408b-8ee8-1fb626017228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['春', 'の', '山', 'に', '花', 'が', '咲い', 'て', 'いる']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_obj = dictionary.Dictionary(dict=\"full\").create()\n",
    "\n",
    "mode = tokenizer.Tokenizer.SplitMode.A\n",
    "[m.surface() for m in tokenizer_obj.tokenize(\"春の山に花が咲いている\", mode)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3316e5-d784-4f66-b38f-7f624a2ea6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SudachiPyの辞書を「full」で初期化（季語などにも対応可能）\n",
    "tokenizer_obj = dictionary.Dictionary(dict=\"full\").create()\n",
    "split_mode = tokenizer.Tokenizer.SplitMode.A  # AはSudachiPyの中で最も細かい形で分かち書きするモード\n",
    "\n",
    "# 単語とIDを紐づける辞書（存在しない単語には自動的に新しいIDを割り当てる）\n",
    "word2id = defaultdict(lambda: len(word2id))\n",
    "word2id[\"<PAD>\"] = 0  # パディング用（固定長処理などで使用）\n",
    "word2id[\"<UNK>\"] = 1  # 未知語用（辞書に存在しない単語）\n",
    "\n",
    "# 特殊の発音\n",
    "SPECIAL_READINGS = {\n",
    "    \"汝\": \"ナレ\",\n",
    "    \"我\": \"ワレ\",\n",
    "    \"行く\": \"ユク\",\n",
    "    \"二十歳\": \"ハタチ\",\n",
    "    \"故郷\": \"フルサト\",\n",
    "}\n",
    "\n",
    "# 踊り字の処理\n",
    "def replace_iteration_marks(text):\n",
    "    result = \"\"\n",
    "    prev = \"\"\n",
    "\n",
    "    hira_dakuon_map = {\n",
    "        \"か\":\"が\", \"き\":\"ぎ\", \"く\":\"ぐ\", \"け\":\"げ\", \"こ\":\"ご\",\n",
    "        \"さ\":\"ざ\", \"し\":\"じ\", \"す\":\"ず\", \"せ\":\"ぜ\", \"そ\":\"ぞ\",\n",
    "        \"た\":\"だ\", \"ち\":\"ぢ\", \"つ\":\"づ\", \"て\":\"で\", \"と\":\"ど\",\n",
    "        \"は\":\"ば\", \"ひ\":\"び\", \"ふ\":\"ぶ\", \"へ\":\"べ\", \"ほ\":\"ぼ\"\n",
    "    }\n",
    "\n",
    "    kata_dakuon_map = {\n",
    "        \"カ\":\"ガ\", \"キ\":\"ギ\", \"ク\":\"グ\", \"ケ\":\"ゲ\", \"コ\":\"ゴ\",\n",
    "        \"サ\":\"ザ\", \"シ\":\"ジ\", \"ス\":\"ズ\", \"セ\":\"ゼ\", \"ソ\":\"ゾ\",\n",
    "        \"タ\":\"ダ\", \"チ\":\"ヂ\", \"ツ\":\"ヅ\", \"テ\":\"デ\", \"ト\":\"ド\",\n",
    "        \"ハ\":\"バ\", \"ヒ\":\"ビ\", \"フ\":\"ブ\", \"ヘ\":\"ベ\", \"ホ\":\"ボ\"\n",
    "    }\n",
    "\n",
    "    for ch in text:\n",
    "        if ch == \"ゝ\":\n",
    "            result += prev\n",
    "        elif ch == \"ゞ\":\n",
    "            result += hira_dakuon_map.get(prev, prev)\n",
    "        elif ch == \"ヽ\":\n",
    "            result += prev\n",
    "        elif ch == \"ヾ\":\n",
    "            result += kata_dakuon_map.get(prev, prev)\n",
    "        else:\n",
    "            result += ch\n",
    "            prev = ch\n",
    "    return result\n",
    "\n",
    "\n",
    "# メイン処理\n",
    "def preprocess_haiku(text):\n",
    "    # 踊り字の前処理\n",
    "    text = replace_iteration_marks(text)\n",
    "    tokens = tokenizer_obj.tokenize(text, split_mode)\n",
    "    tokens_combined = []\n",
    "\n",
    "    for m in tokens:\n",
    "        surface = m.normalized_form()  # 元の表記の正規化（例：花、咲い）\n",
    "        kana = SPECIAL_READINGS.get(surface)\n",
    "        if kana is None:\n",
    "            kana = pyopenjtalk.g2p(surface, kana=True)  # 片仮名に変換\n",
    "            kana = kana.replace(\" \", \"\").replace(\"、\", \"\").replace(\"。\", \"\")  # 空白や記号を除去\n",
    "\n",
    "        if kana:\n",
    "            dict_form = m.dictionary_form()       # 辞書形（例：食べ → 食べる）\n",
    "            pos = m.part_of_speech()[0]           # 単語の分類（例：動詞、名詞など）\n",
    "            combined = f\"{surface}/{kana}/{dict_form}/{pos}\"  # 複合化\n",
    "            tokens_combined.append(combined)\n",
    "\n",
    "    # 単語をIDに変換（すでに存在するものは同じID、新規は追加）\n",
    "    ids = [word2id[token] for token in tokens_combined]\n",
    "\n",
    "    return tokens_combined, ids  #リストを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f0d2ff-7f24-4575-abd2-2d0a64c16705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春/ハル/春/名詞', 'も/モ/も/助詞', '早い/ハヤイ/早い/形容詞', '山吹/ヤマブキ/山吹/名詞', '白い/シロイ/白い/形容詞', '苣苦/苣苦/苣苦/名詞', '為る/ナル/する/動詞']\n",
      "ID： [10, 11, 12, 13, 14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "text = \"春も早山吹白く苣苦し\"\n",
    "\n",
    "kana_list, ids = preprocess_haiku(text)\n",
    "\n",
    "print(kana_list)\n",
    "print(\"ID：\", ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ce49682-7bda-43d5-ab43-f8b176c3a769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID           Haiku\n",
      "0   1      春も早山吹白く苣苦し\n",
      "1   2      山寺の春や仏に水仙花\n",
      "2   3  門口に風呂たく春のとまりかな\n",
      "3   4   雪の絵を春も掛けたる埃かな\n",
      "4   5  起重機の手挙げて立てり海は春\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/haiku_dataset.csv\", encoding=\"utf-8\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f5413c8-bba6-49c7-9930-fa2c22392c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    haiku_text = row[\"Haiku\"]\n",
    "    kana_list, ids = preprocess_haiku(haiku_text)\n",
    "    processed_data.append({\n",
    "        \"ID\": row[\"ID\"],\n",
    "        \"Haiku\": haiku_text,\n",
    "        \"Tokens\": kana_list,\n",
    "        \"IDs\": ids\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11455e84-b66b-4fa5-b295-cefb6412075c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID           Haiku                                             Tokens  \\\n",
      "0   1      春も早山吹白く苣苦し  [春/ハル/春/名詞, も/モ/も/助詞, 早い/ハヤイ/早い/形容詞, 山吹/ヤマブキ/山...   \n",
      "1   2      山寺の春や仏に水仙花  [山寺/ヤマデラ/山寺/名詞, の/ノ/の/助詞, 春/ハル/春/名詞, や/ヤ/や/助詞,...   \n",
      "2   3  門口に風呂たく春のとまりかな  [門口/カドグチ/門口/名詞, に/ニ/に/助詞, 風呂/フロ/風呂/名詞, たい/タイ/た...   \n",
      "3   4   雪の絵を春も掛けたる埃かな  [雪/ユキ/雪/名詞, の/ノ/の/助詞, 絵/エ/絵/名詞, を/ヲ/を/助詞, 春/ハル...   \n",
      "4   5  起重機の手挙げて立てり海は春  [起重/キジュー/起重/名詞, 機/キ/機/名詞, の/ノ/の/助詞, 手/テ/手/名詞, ...   \n",
      "\n",
      "                                            IDs  \n",
      "0                  [10, 11, 12, 13, 14, 15, 16]  \n",
      "1                  [17, 18, 10, 19, 20, 21, 22]  \n",
      "2          [23, 21, 24, 25, 10, 18, 26, 27, 28]  \n",
      "3  [29, 18, 30, 31, 10, 11, 32, 33, 34, 27, 28]  \n",
      "4  [35, 36, 18, 37, 38, 39, 40, 41, 42, 43, 10]  \n"
     ]
    }
   ],
   "source": [
    "processed_df = pd.DataFrame(processed_data)\n",
    "processed_df.to_csv(\"dataset/processed_haiku.csv\", index=False, encoding=\"utf-8\")\n",
    "print(processed_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
